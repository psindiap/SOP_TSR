{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "deepnote_to_be_reexecuted": false,
    "source_hash": "937d301f",
    "execution_start": 1650301650515,
    "execution_millis": 20964,
    "cell_id": "55726b49-7836-42c0-aecc-680a669598a2",
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 861.1875
   },
   "source": "!pip install Embeddings==0.0.8\n!pip install np_utils\n!pip install scikit-plot\n!pip install gensim==3.8.3\n!pip install vecstack\nimport nltk\nnltk.download('stopwords')",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "text": "Requirement already satisfied: Embeddings==0.0.8 in /root/venv/lib/python3.7/site-packages (0.0.8)\nRequirement already satisfied: numpy in /shared-libs/python3.7/py/lib/python3.7/site-packages (from Embeddings==0.0.8) (1.21.5)\nRequirement already satisfied: requests in /shared-libs/python3.7/py/lib/python3.7/site-packages (from Embeddings==0.0.8) (2.27.1)\nRequirement already satisfied: tqdm in /shared-libs/python3.7/py/lib/python3.7/site-packages (from Embeddings==0.0.8) (4.63.0)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /shared-libs/python3.7/py/lib/python3.7/site-packages (from requests->Embeddings==0.0.8) (1.26.9)\nRequirement already satisfied: idna<4,>=2.5; python_version >= \"3\" in /shared-libs/python3.7/py-core/lib/python3.7/site-packages (from requests->Embeddings==0.0.8) (3.3)\nRequirement already satisfied: certifi>=2017.4.17 in /shared-libs/python3.7/py/lib/python3.7/site-packages (from requests->Embeddings==0.0.8) (2021.10.8)\nRequirement already satisfied: charset-normalizer~=2.0.0; python_version >= \"3\" in /shared-libs/python3.7/py-core/lib/python3.7/site-packages (from requests->Embeddings==0.0.8) (2.0.12)\n\u001b[33mWARNING: You are using pip version 20.1.1; however, version 22.0.4 is available.\nYou should consider upgrading via the '/root/venv/bin/python -m pip install --upgrade pip' command.\u001b[0m\nRequirement already satisfied: np_utils in /root/venv/lib/python3.7/site-packages (0.6.0)\nRequirement already satisfied: numpy>=1.0 in /shared-libs/python3.7/py/lib/python3.7/site-packages (from np_utils) (1.21.5)\n\u001b[33mWARNING: You are using pip version 20.1.1; however, version 22.0.4 is available.\nYou should consider upgrading via the '/root/venv/bin/python -m pip install --upgrade pip' command.\u001b[0m\nRequirement already satisfied: scikit-plot in /root/venv/lib/python3.7/site-packages (0.3.7)\nRequirement already satisfied: joblib>=0.10 in /shared-libs/python3.7/py/lib/python3.7/site-packages (from scikit-plot) (1.1.0)\nRequirement already satisfied: scikit-learn>=0.18 in /shared-libs/python3.7/py/lib/python3.7/site-packages (from scikit-plot) (1.0.2)\nRequirement already satisfied: scipy>=0.9 in /shared-libs/python3.7/py/lib/python3.7/site-packages (from scikit-plot) (1.7.3)\nRequirement already satisfied: matplotlib>=1.4.0 in /shared-libs/python3.7/py/lib/python3.7/site-packages (from scikit-plot) (3.5.1)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /shared-libs/python3.7/py/lib/python3.7/site-packages (from scikit-learn>=0.18->scikit-plot) (3.1.0)\nRequirement already satisfied: numpy>=1.14.6 in /shared-libs/python3.7/py/lib/python3.7/site-packages (from scikit-learn>=0.18->scikit-plot) (1.21.5)\nRequirement already satisfied: cycler>=0.10 in /shared-libs/python3.7/py/lib/python3.7/site-packages (from matplotlib>=1.4.0->scikit-plot) (0.11.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /shared-libs/python3.7/py/lib/python3.7/site-packages (from matplotlib>=1.4.0->scikit-plot) (1.4.0)\nRequirement already satisfied: pillow>=6.2.0 in /shared-libs/python3.7/py/lib/python3.7/site-packages (from matplotlib>=1.4.0->scikit-plot) (9.0.1)\nRequirement already satisfied: python-dateutil>=2.7 in /shared-libs/python3.7/py-core/lib/python3.7/site-packages (from matplotlib>=1.4.0->scikit-plot) (2.8.2)\nRequirement already satisfied: fonttools>=4.22.0 in /shared-libs/python3.7/py/lib/python3.7/site-packages (from matplotlib>=1.4.0->scikit-plot) (4.31.2)\nRequirement already satisfied: pyparsing>=2.2.1 in /shared-libs/python3.7/py-core/lib/python3.7/site-packages (from matplotlib>=1.4.0->scikit-plot) (3.0.7)\nRequirement already satisfied: packaging>=20.0 in /shared-libs/python3.7/py-core/lib/python3.7/site-packages (from matplotlib>=1.4.0->scikit-plot) (21.3)\nRequirement already satisfied: typing-extensions; python_version < \"3.8\" in /shared-libs/python3.7/py-core/lib/python3.7/site-packages (from kiwisolver>=1.0.1->matplotlib>=1.4.0->scikit-plot) (4.1.1)\nRequirement already satisfied: six>=1.5 in /shared-libs/python3.7/py-core/lib/python3.7/site-packages (from python-dateutil>=2.7->matplotlib>=1.4.0->scikit-plot) (1.16.0)\n\u001b[33mWARNING: You are using pip version 20.1.1; however, version 22.0.4 is available.\nYou should consider upgrading via the '/root/venv/bin/python -m pip install --upgrade pip' command.\u001b[0m\nRequirement already satisfied: gensim==3.8.3 in /root/venv/lib/python3.7/site-packages (3.8.3)\nRequirement already satisfied: scipy>=0.18.1 in /shared-libs/python3.7/py/lib/python3.7/site-packages (from gensim==3.8.3) (1.7.3)\nRequirement already satisfied: six>=1.5.0 in /shared-libs/python3.7/py-core/lib/python3.7/site-packages (from gensim==3.8.3) (1.16.0)\nRequirement already satisfied: numpy>=1.11.3 in /shared-libs/python3.7/py/lib/python3.7/site-packages (from gensim==3.8.3) (1.21.5)\nRequirement already satisfied: smart-open>=1.8.1 in /shared-libs/python3.7/py/lib/python3.7/site-packages (from gensim==3.8.3) (5.2.1)\n\u001b[33mWARNING: You are using pip version 20.1.1; however, version 22.0.4 is available.\nYou should consider upgrading via the '/root/venv/bin/python -m pip install --upgrade pip' command.\u001b[0m\nRequirement already satisfied: vecstack in /root/venv/lib/python3.7/site-packages (0.4.0)\nRequirement already satisfied: scipy in /shared-libs/python3.7/py/lib/python3.7/site-packages (from vecstack) (1.7.3)\nRequirement already satisfied: numpy in /shared-libs/python3.7/py/lib/python3.7/site-packages (from vecstack) (1.21.5)\nRequirement already satisfied: scikit-learn>=0.18 in /shared-libs/python3.7/py/lib/python3.7/site-packages (from vecstack) (1.0.2)\nRequirement already satisfied: joblib>=0.11 in /shared-libs/python3.7/py/lib/python3.7/site-packages (from scikit-learn>=0.18->vecstack) (1.1.0)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /shared-libs/python3.7/py/lib/python3.7/site-packages (from scikit-learn>=0.18->vecstack) (3.1.0)\n\u001b[33mWARNING: You are using pip version 20.1.1; however, version 22.0.4 is available.\nYou should consider upgrading via the '/root/venv/bin/python -m pip install --upgrade pip' command.\u001b[0m\n[nltk_data] Downloading package stopwords to /root/nltk_data...\n[nltk_data]   Unzipping corpora/stopwords.zip.\n",
     "output_type": "stream"
    },
    {
     "output_type": "execute_result",
     "execution_count": 1,
     "data": {
      "text/plain": "True"
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "deepnote_to_be_reexecuted": false,
    "source_hash": "22802d86",
    "execution_start": 1650301671493,
    "execution_millis": 8074,
    "cell_id": "00001-6014f502-1c3d-4238-a06c-91581ec71b85",
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 802.796875
   },
   "source": "#!/usr/bin/env python3\n# -*- coding: utf-8 -*-\n\n\"\"\"\nFake news detection\nLSTM model\n\"\"\"\nimport getEmbeddings\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom tensorflow import keras \nfrom tensorflow.keras import backend as K\nimport pandas as pd\nimport np_utils\nfrom sklearn.linear_model import LinearRegression\nfrom vecstack import stacking\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout, LSTM, Embedding, Input, RepeatVector,Bidirectional\nfrom tensorflow.keras.optimizers import SGD\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\nimport scikitplot.plotters as skplt\nimport os\nfrom tensorflow.keras.datasets import imdb\nfrom tensorflow.keras.layers import Embedding\nfrom tensorflow.keras.preprocessing import sequence\nfrom collections import Counter\nimport matplotlib.pyplot as plt\nfrom sklearn.linear_model import LogisticRegression\n\n\n\ntop_words = 5000\nepoch_num = 8\nbatch_size = 128\n\n\n",
   "execution_count": null,
   "outputs": [
    {
     "name": "stderr",
     "text": "[nltk_data] Downloading package stopwords to /root/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "deepnote_to_be_reexecuted": false,
    "source_hash": "549066d0",
    "execution_start": 1650301679570,
    "execution_millis": 5,
    "cell_id": "00002-c6b0c3d6-8c0a-424b-9583-8a2ef8e56f05",
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 81
   },
   "source": "import pickle",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "c976051e84af4695bc24babb8bcd499b",
    "tags": [],
    "deepnote_to_be_reexecuted": false,
    "source_hash": "7b77907e",
    "execution_start": 1650301679578,
    "execution_millis": 15126,
    "owner_user_id": "90d8e9a7-4cf7-49f2-843d-0f73d1ab4387",
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 657
   },
   "source": "from sklearn.model_selection import train_test_split\ntrain_ratio = 0.70\nvalidation_ratio = 0.20\ntest_ratio = 0.10\n\n\npath = 'datasets/train.csv'\nvector_dimension=300\n\ndata = pd.read_csv(path)\n\nmissing_rows = []\nfor i in range(len(data)):\n        if data.loc[i, 'text'] != data.loc[i, 'text']:\n            missing_rows.append(i)\ndata = data.drop(missing_rows).reset_index().drop(['index','id'],axis=1)\n\nfor i in range(len(data)):\n        data.loc[i, 'text'] = getEmbeddings.cleanup(data.loc[i,'text'])\n\ndata = data.sample(frac=1).reset_index(drop=True)\n\nx_l = data.loc[:,'text'].values\ny_l = data.loc[:,'label'].values\ny_l = np.where(y_l<1, 1, 0)\n\n\nxtr, xte, y_train, y_test = train_test_split(\n    x_l, y_l, test_size=1 - train_ratio)\n \n# performing test validation split\nxvl, xte, y_val, y_test = train_test_split(\n    xte, y_test, test_size=test_ratio/(test_ratio + validation_ratio))",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "deepnote_to_be_reexecuted": false,
    "source_hash": "aca9103b",
    "execution_start": 1650301694724,
    "execution_millis": 1244,
    "cell_id": "00004-f9ed718f-3f21-419b-bfb8-b0675850efd1",
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 477
   },
   "source": "\n# # Read the text data\n# if not os.path.isfile('./xtr_shuffled.npy') or \\\n#     not os.path.isfile('./xte_shuffled.npy') or \\\n#     not os.path.isfile('./ytr_shuffled.npy') or \\\n#     not os.path.isfile('./yte_shuffled.npy'):\n#     getEmbeddings.clean_data()\n\n\n# xtr = np.load('./xtr_shuffled.npy', allow_pickle=True)\n# xte = np.load('./xte_shuffled.npy', allow_pickle=True)\n# y_train = np.load('./ytr_shuffled.npy', allow_pickle=True)\n# y_test = np.load('./yte_shuffled.npy', allow_pickle=True)\n\ncnt = Counter()\nx_train = []\nfor x in xtr:\n    x_train.append(x.split())\n    for word in x_train[-1]:\n        cnt[word] += 1  \n\n\n",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "deepnote_to_be_reexecuted": false,
    "source_hash": "18ed0683",
    "execution_start": 1650301696049,
    "execution_millis": 5,
    "cell_id": "00005-b54e3ceb-10b7-4631-a859-19a88a0815fb",
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 225
   },
   "source": "# Storing most common words\nmost_common = cnt.most_common(top_words + 1)\nword_bank = {}\nid_num = 1\nfor word, freq in most_common:\n    word_bank[word] = id_num\n    id_num += 1\n\n",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "deepnote_to_be_reexecuted": false,
    "source_hash": "371e1a87",
    "execution_start": 1650301696083,
    "execution_millis": 1165,
    "cell_id": "00006-0c1989ac-d428-4109-b697-1b36a22fdd2f",
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 315
   },
   "source": "# Encode the sentences\nfor news in x_train:\n    i = 0\n    while i < len(news):\n        if news[i] in word_bank:\n            news[i] = word_bank[news[i]]\n            i += 1\n        else:\n            del news[i]\n\ny_train = list(y_train)\ny_test = list(y_test)\ny_val=list(y_val)\n",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "deepnote_to_be_reexecuted": false,
    "source_hash": "fb6a6ecc",
    "execution_start": 1650301697251,
    "execution_millis": 701,
    "cell_id": "00007-18d0b063-e313-46f8-81d9-c86e7e5329d7",
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 963
   },
   "source": "# Delete the short news\ni = 0\nwhile i < len(x_train):\n    if len(x_train[i]) > 10:\n        i += 1\n    else:\n        del x_train[i]\n        del y_train[i]\n\n# Generating test data\nx_test = []\nfor x in xte:\n    x_test.append(x.split())\n\n# Encode the sentences\nfor news in x_test:\n    i = 0\n    while i < len(news):\n        if news[i] in word_bank:\n            news[i] = word_bank[news[i]]\n            i += 1\n        else:\n            del news[i]\n\n\n# Generating val data\nx_val = []\nfor x in xvl:\n    x_val.append(x.split())\n\n# Encode the sentences\nfor news in x_val:\n    i = 0\n    while i < len(news):\n        if news[i] in word_bank:\n            news[i] = word_bank[news[i]]\n            i += 1\n        else:\n            del news[i]\n\n# Truncate and pad input sequences\nmax_review_length = 300\nX_train = sequence.pad_sequences(x_train, maxlen=max_review_length)\nX_test = sequence.pad_sequences(x_test, maxlen=max_review_length)\nX_val = sequence.pad_sequences(x_val, maxlen=max_review_length)\n\n# Convert to numpy arrays\ny_train = np.array(y_train)\ny_test = np.array(y_test)\ny_val=np.array(y_val)",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "8adff166e4b84017bbbf4e1475532a20",
    "tags": [],
    "deepnote_to_be_reexecuted": false,
    "source_hash": "fb199d4f",
    "execution_start": 1650301697957,
    "execution_millis": 4,
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 188
   },
   "source": "print(X_train.shape)\nprint(X_test.shape)\nprint(y_test.shape)",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "text": "(6770, 300)\n(1000, 300)\n(1000,)\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "bc4ab7521a464321bac434b25eec42ad",
    "tags": [],
    "deepnote_to_be_reexecuted": false,
    "source_hash": "d9e61964",
    "execution_start": 1650301697964,
    "execution_millis": 8788,
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 207
   },
   "source": "\nwith open('lstm.sav' , 'rb') as f:\n    model_1 = pickle.load(f)\nwith open('blstm.sav' , 'rb') as f:\n    model_2 = pickle.load(f)\n \n# putting all base model objects in one list\nall_models = [model_1, model_2]",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "d10089fbff674c3d8f62d18030f5cd74",
    "tags": [],
    "deepnote_to_be_reexecuted": false,
    "source_hash": "69054a29",
    "execution_start": 1650301706753,
    "execution_millis": 66514,
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 594.796875
   },
   "source": "# training first model\nmodel_1.fit(X_train, y_train)\nval_pred_1 = model_1.predict(X_val)\ntest_pred_1 = model_1.predict(X_test)\n \n# converting to dataframe\nval_pred_1 = pd.DataFrame(val_pred_1)\ntest_pred_1 = pd.DataFrame(test_pred_1)\nprint(val_pred_1)\n\n\n",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "text": "212/212 [==============================] - 60s 271ms/step - loss: 0.4747 - accuracy: 0.7770\n             0\n0     0.335436\n1     0.204804\n2     0.006687\n3     0.945411\n4     0.990548\n...        ...\n1994  0.479968\n1995  0.651401\n1996  0.053351\n1997  0.929568\n1998  0.135192\n\n[1999 rows x 1 columns]\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "d4a31f15a3224e478d6871656bfea80d",
    "tags": [],
    "deepnote_to_be_reexecuted": false,
    "source_hash": "9610e3f0",
    "execution_start": 1650301773271,
    "execution_millis": 6,
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 206
   },
   "source": "\nprint(test_pred_1.shape)\nprint(val_pred_1.shape)\nprint(len(x))",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "text": "(1000, 1)\n(1999, 1)\n2416\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "0261e4610449471ab727a83a48260ad7",
    "tags": [],
    "deepnote_to_be_reexecuted": false,
    "source_hash": "fbcbce6d",
    "execution_start": 1650301773295,
    "execution_millis": 115484,
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 242.796875
   },
   "source": "# training second model\nmodel_2.fit(X_train, y_train)\nval_pred_2 = model_2.predict(X_val)\ntest_pred_2 = model_2.predict(X_test)\n \n# converting to dataframe\nval_pred_2 = pd.DataFrame(val_pred_2)\ntest_pred_2 = pd.DataFrame(test_pred_2)",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "text": "212/212 [==============================] - 105s 477ms/step - loss: 0.4573 - accuracy: 0.7897\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "9390cdb5305e41779530f263fab2099c",
    "tags": [],
    "deepnote_to_be_reexecuted": false,
    "source_hash": "9e29b07f",
    "execution_start": 1650301888785,
    "execution_millis": 9,
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 171
   },
   "source": "X_val = pd.DataFrame(X_val)\nval_pred_1 = pd.DataFrame(val_pred_1)\nval_pred_2 = pd.DataFrame(val_pred_2)\ndf_val = pd.concat([X_val, val_pred_1, val_pred_2], axis=1)\ndf_val=np.array(df_val)\n",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "28cc2c08cccf49b296b09944ad22fcd7",
    "tags": [],
    "deepnote_to_be_reexecuted": false,
    "source_hash": "5b428b84",
    "execution_start": 1650301888800,
    "execution_millis": 2,
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 153
   },
   "source": "X_test = pd.DataFrame(X_test)\ntest_pred_1 = pd.DataFrame(test_pred_1)\ntest_pred_2 = pd.DataFrame(test_pred_2)\ndf_test = pd.concat([X_test, test_pred_1, test_pred_2], axis=1)\ndf_test=np.array(df_test)",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "58edff03b1a94a05805c8e29e2d3181a",
    "tags": [],
    "deepnote_to_be_reexecuted": false,
    "source_hash": "12335e69",
    "execution_start": 1650301888807,
    "execution_millis": 3,
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 394.796875
   },
   "source": "print(df_val)\nprint(y_val)",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "text": "[[0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 3.45800000e+03\n  3.35436463e-01 6.66111648e-01]\n [1.47900000e+03 1.23500000e+03 1.64800000e+03 ... 2.66400000e+03\n  2.04804033e-01 1.08181685e-01]\n [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 1.80600000e+03\n  6.68725371e-03 2.51169801e-02]\n ...\n [1.60500000e+03 7.58000000e+02 2.22000000e+02 ... 1.22600000e+03\n  5.33505380e-02 1.04141444e-01]\n [7.89000000e+02 1.46000000e+02 6.60000000e+01 ... 4.38000000e+02\n  9.29568410e-01 7.74455488e-01]\n [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 2.66400000e+03\n  1.35192454e-01 8.94267857e-02]]\n[1 0 0 ... 0 1 0]\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "045e8b584015402f9c7878aebda59cec",
    "tags": [],
    "deepnote_to_be_reexecuted": false,
    "source_hash": "b232bdf",
    "execution_start": 1650301888817,
    "execution_millis": 90,
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 207
   },
   "source": "# concatenating validation dataset along with all the predicted validation data (meta features)\n# making the final model using the meta features\n# final_model=LogisticRegression(solver='liblinear', random_state=0)\nfinal_model = LinearRegression()\nfinal_model.fit(df_val, y_val)\n \n# getting the final output\nfinal_pred = final_model.predict(df_test)",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "c3491236ce404e459ab392c4d1878464",
    "tags": [],
    "deepnote_to_be_reexecuted": false,
    "source_hash": "4e41e03c",
    "execution_start": 1650301888918,
    "execution_millis": 38,
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 351
   },
   "source": "\n \n# # computing the stack features\n# s_train, s_test = stacking(all_models, X_train, y_train, X_test,regression = True, n_folds = 4, shuffle=True )\n \n# # initializing the second-level model\n# final_model = model_1\n \n# # fitting the second level model with stack features\n# final_model = final_model.fit(s_train, y_train)\n \n# # predicting the final output using stacking\n# pred_final = final_model.predict(X_test)\n \n# # printing the root mean squared error between real value and predicted value\n# # print(mean_squared_error(y_test, pred_final))",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "bc1fdcd9916f436cb32d4bc34a3db3fe",
    "tags": [],
    "deepnote_to_be_reexecuted": false,
    "source_hash": "cfdf59da",
    "execution_start": 1650301888956,
    "execution_millis": 42,
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 99
   },
   "source": "y_pred = final_pred\ny_pred = np.where(y_pred>0.5, 1, 0)",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "0335523dd71b4da18a2f46461557335f",
    "tags": [],
    "deepnote_to_be_reexecuted": false,
    "source_hash": "2a99353b",
    "execution_start": 1650301888998,
    "execution_millis": 13,
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 701
   },
   "source": "print(final_pred)",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "text": "[ 3.98783058e-02  4.39933287e-01 -5.03562343e-02  3.91005344e-01\n  9.57624024e-01  5.45518431e-01  4.21804044e-02  9.31859579e-01\n  3.48728961e-01  9.60197954e-01  1.66267124e-01  1.00006976e+00\n -1.82782518e-01  1.00852645e-01  1.85979894e-01 -4.51961385e-01\n  7.98690507e-01  4.73628636e-01  6.79942117e-01  5.16889283e-01\n  7.63189171e-01 -7.39936559e-02 -5.79165617e-02  7.40575891e-01\n  1.28012343e+00  8.48135632e-01  1.01758750e+00  2.27341169e-01\n  1.02428343e-02  3.73073787e-02  9.23077095e-01  3.16274733e-02\n  2.48090319e-01  7.52624709e-01 -7.66501161e-02 -1.62053338e-02\n  1.25683658e+00  3.36155773e-01  6.58062134e-01  1.07310926e+00\n  1.07215238e+00  4.33977791e-01  1.00270711e+00  1.35178415e+00\n  2.49372014e-01  3.90021015e-01 -1.24714730e-01  9.84696066e-01\n  1.19960676e+00 -1.20553355e-01  4.48872536e-01 -1.93920372e-01\n  1.59082927e-01  1.10287455e+00  4.22945773e-01  1.06985274e-01\n  9.06544599e-01  4.62127638e-02 -3.66564667e-02  1.19028764e+00\n  5.50694604e-01  6.79396664e-01  9.65771177e-01  5.49645929e-02\n  1.05642668e+00 -6.08627869e-02  3.90021015e-01  1.00273288e+00\n  7.54148637e-01  1.05555691e+00  7.83170673e-01  6.64698148e-02\n -7.10760287e-02  2.14069315e-01  9.99953625e-01  8.08186093e-01\n  1.01960892e+00  3.90021015e-01  7.27193967e-01  4.74884289e-02\n  9.51321899e-01  3.22986397e-01  8.77904723e-01  9.64107642e-01\n  1.08086682e+00  9.64450750e-01  1.25003516e-01  1.06124516e+00\n  1.01726941e+00  8.38908038e-01  1.47627661e-02  2.89588977e-01\n  2.85136117e-03  7.41817127e-01  1.07886459e+00  3.72477484e-01\n  8.61528521e-01  7.89011470e-01 -3.39760282e-01  8.09838082e-01\n  8.30640913e-01 -3.27608455e-02  1.11237112e-01  5.36686929e-02\n  8.00653384e-01  3.90021015e-01  5.91347723e-01 -5.01587736e-03\n  2.51057456e-01 -5.33238956e-02 -9.90403316e-02  3.97797025e-01\n -1.66945118e-01  1.05803939e+00 -1.01783052e-03  1.25869309e-01\n  7.86293803e-01  8.11557525e-01  3.90021015e-01  9.02352343e-01\n  4.44662566e-02  8.94453272e-01  7.28075715e-01  8.16865775e-01\n -1.29144816e-02  8.52107339e-04  2.30366592e-01  9.46149041e-01\n  6.83722224e-01  6.46422358e-02 -2.12043595e-02  1.12744100e+00\n  1.19687421e-01  5.46939879e-01  1.08530603e+00  9.34129874e-01\n  3.41796786e-01  2.18769084e-01  2.46873377e-01  1.58064963e-01\n  9.09575329e-02  9.23546440e-01  2.09980440e-01  8.86900411e-01\n  1.78560571e-01  1.11461923e-01  1.75575200e-01  3.06419345e-01\n -7.83905207e-02  7.36360752e-01  9.34111172e-01  7.15462175e-01\n  8.97210889e-01  2.00929895e-01  9.17168576e-02  1.06322435e+00\n  2.73042189e-01  1.41295496e+00  7.50902930e-01  9.15989592e-01\n  7.97478708e-01  1.18780999e+00  1.23435555e+00  1.17963956e+00\n  1.85230018e-01  3.63023448e-03  1.04405850e+00 -1.73443775e-01\n -2.20773268e-01 -8.68548615e-02  1.18484965e+00  2.49642280e-01\n  6.11958508e-01  6.73546979e-01  1.72703975e-01  8.45965486e-01\n  7.16174851e-01  8.09228859e-01  4.12537220e-01  3.96102418e-01\n  9.93792800e-01  7.96277752e-02  4.86233108e-01  3.90021015e-01\n  8.52427009e-01  1.13417124e+00  2.03255171e-01  1.37835587e-01\n -2.67585907e-03  1.02538377e+00  7.46631656e-01  9.49081519e-01\n  1.02214823e+00  7.82262411e-02  7.98414534e-01  1.02323620e+00\n  8.60119849e-01 -2.14001033e-01  9.65081940e-01  7.23796514e-01\n  1.07067260e+00 -2.17353093e-02 -7.06845702e-02  8.45830522e-01\n  9.70536360e-01  1.31862413e-01 -4.45729619e-02  1.68662052e-01\n  8.98196268e-01  9.44067827e-01  1.02751667e+00  4.19014560e-02\n  1.09838484e-01  9.89632639e-01  6.49703238e-01  9.81569866e-01\n  5.13041265e-02  1.30253853e-01  4.40619537e-01 -1.22287290e-01\n  8.86891528e-01  5.25259323e-02  1.33000560e-01  5.50237878e-01\n  1.91339557e-01  5.51758371e-01  6.98430920e-01  6.73156005e-01\n  7.51935832e-01  8.38333610e-01  1.19766256e+00  9.65934107e-01\n  9.89475312e-01  5.69138570e-01  2.57402352e-01  8.48206849e-01\n -1.12085780e-01  2.48853100e-01  9.85001895e-01 -1.23552376e-01\n  4.38965453e-01 -5.34565459e-02  8.40639748e-01  9.60008856e-01\n -1.03778615e-02  1.00902905e+00  1.34966090e-01  2.31173329e-01\n  9.70099587e-01  9.67789349e-01  5.27364483e-01  8.94801809e-01\n -1.06624468e-01  2.07844842e-01  3.36378341e-01  9.86321049e-01\n  3.32705854e-01  8.86737817e-01  1.65915964e-01  7.48465559e-01\n  8.29139636e-02  3.90021015e-01  1.21640545e-01  2.08736689e-01\n  1.30151230e-01  4.80175569e-01  7.80576927e-02  1.04880046e+00\n -1.61862252e-01  8.19146935e-01  6.73236233e-01  9.08696168e-01\n  4.48596979e-01 -6.44590838e-03  1.84967357e-01  5.75733113e-01\n -6.34082980e-02  3.28072830e-01 -4.51961385e-01  1.03558112e-01\n  1.41902893e-01 -1.61993049e-01 -8.61387385e-02  6.50886009e-01\n  8.22398452e-01  8.08578273e-01  7.25483757e-01  5.19771359e-01\n  5.69794978e-01  5.35942594e-02  2.83870566e-01  7.65619482e-01\n  2.64117578e-01  2.78628351e-01  7.12443825e-01  9.03313614e-01\n  3.29816365e-01 -4.42787054e-02  1.34647175e-01  8.04468011e-01\n -1.87046256e-01  1.08891864e+00  6.87568009e-01  3.13164788e-01\n  8.24014218e-01  8.00647465e-01  7.29541506e-01  9.23309965e-01\n  3.65609555e-01  9.21847428e-01  1.00798820e+00  7.28179637e-01\n  3.34640233e-01  2.74655891e-01  6.27073132e-01  6.83910021e-01\n  4.38524560e-01  5.64315806e-01  6.23597541e-01  8.70426604e-01\n  1.60210933e-01 -1.57785802e-01  5.75247099e-02 -8.46837172e-02\n  3.15708335e-02  1.49749163e-01  8.04798813e-01  1.12667998e+00\n  9.49615231e-01  3.25285356e-02 -1.13674527e-01  1.01804400e+00\n  6.02070041e-01  1.64020217e-01 -2.90976300e-02  1.05100970e+00\n  9.20999830e-01  1.17910550e-01 -9.73753102e-03  1.27610924e+00\n  4.75511326e-01  5.60557694e-01  1.00366013e+00  5.68605634e-02\n  6.87080972e-01  9.71687674e-01  3.90021015e-01 -4.25856073e-02\n  8.82756594e-01  6.50444338e-01  4.19162153e-02  1.05184717e+00\n  2.38195486e-01  8.29213165e-01  5.50262436e-01  3.00912833e-01\n  9.67407950e-01  2.04271254e-02  8.53666144e-02  6.64761832e-01\n  8.02440555e-02  2.20905643e-01 -1.25530373e-01  9.14803669e-01\n  9.24818534e-01  2.84087894e-01  9.94842105e-01 -3.63003120e-02\n -6.51415811e-02  2.28940312e-01 -1.95123788e-02  8.49587165e-01\n  7.54940238e-02  1.05164576e+00 -2.58201252e-02  7.61675234e-01\n  9.52887109e-01  1.47484312e-01 -6.71868696e-02 -9.78611948e-02\n  1.00319205e+00  9.14763000e-01 -2.23054250e-02  6.01970431e-01\n  6.81831138e-01  1.37889726e-02  1.26986856e-02  9.97035293e-01\n  1.04096375e+00  2.44679312e-01  1.00166455e+00  6.17298414e-01\n  3.15299878e-01  7.97440135e-01  4.81858678e-01  4.46366563e-01\n -1.39689575e-03  3.84619692e-01  4.87891815e-02  1.39574457e-01\n  9.36823265e-01 -1.23468682e-01 -8.81205896e-02  5.25380928e-01\n -3.96130810e-02  1.02779085e+00  8.12274949e-01 -4.76117232e-02\n  7.11200895e-03 -1.16563765e-01  9.90940109e-01 -2.44603904e-02\n  6.96967519e-01  6.20088950e-01  9.55370160e-03 -5.56506723e-03\n  1.47792037e-01  6.39608108e-01  3.14019423e-01  9.98369127e-01\n  8.48693953e-01  4.43914036e-02  1.21116338e+00  8.05082794e-01\n  2.13730536e-01  5.09628269e-03 -2.42360115e-01  3.69336468e-02\n  1.35543505e-01  7.52403091e-02  9.76117921e-02  1.92860257e-01\n  3.67192460e-01 -3.78929036e-02  3.15464705e-01  4.52170410e-01\n  2.77595194e-01  1.55349431e-01  7.56387854e-01 -4.70217737e-02\n  2.28536568e-01  8.93297604e-01  2.23011546e-01 -6.39152027e-02\n  2.25199804e-01  1.11655892e+00  8.12798337e-01  6.19712760e-01\n  1.25408305e+00  9.21346529e-01  1.25861134e+00  3.18891979e-01\n  9.10519126e-01  6.77896187e-02  4.06842958e-02  7.47070397e-01\n  2.75863941e-01  2.24739107e-01  8.72249581e-01  6.56938713e-01\n  7.05431743e-01  4.75582174e-01 -4.46159790e-02  8.49236473e-01\n  8.44750070e-01  6.95488922e-01  1.16350239e+00  2.19487759e-01\n  7.01545082e-01  9.88390059e-01  3.10218828e-01  8.00836467e-01\n -2.72515206e-02  4.16902458e-01  5.90900136e-01 -7.16283073e-02\n  4.59405307e-02  6.52047268e-01  8.25545368e-01  1.10118018e+00\n  9.43778307e-01  4.86353503e-01  8.64580365e-01  3.12770804e-01\n  2.33622811e-01  1.12280052e-01  6.32744519e-01  7.07339937e-01\n  9.81980759e-01  1.02889443e+00  3.66655471e-01  1.53799733e-02\n -4.26754481e-02  2.21047595e-02  4.87891815e-02 -8.62435000e-02\n -2.02274611e-01 -5.48411870e-02  1.03051153e+00 -1.74552990e-02\n -1.85540086e-01  9.12790687e-01  7.82241318e-01  2.04931473e-01\n  5.52835749e-01  5.89297554e-01  2.85021000e-01  9.24952653e-01\n  9.62635129e-01  1.41899705e+00  2.61920171e-01  9.79291309e-01\n  1.64243421e-02  9.39723488e-01  6.31988735e-01  7.28683945e-01\n  1.15811138e+00  1.77395306e-01  7.39453359e-01 -1.73195873e-03\n  1.25035133e-01  1.21025692e+00  8.10117029e-01  2.86951092e-01\n  2.45574982e-01  2.97554873e-01  1.01100008e+00  4.80477441e-01\n  6.92808150e-01  1.22360585e+00  2.65368487e-01  7.25282956e-02\n -3.35984740e-04  4.34939812e-02  4.82647019e-01 -1.15163255e-01\n  1.06009925e+00  8.23358977e-02 -1.63669589e-01  9.28616483e-01\n  9.60700684e-01 -1.19472761e-02  9.53227853e-01  1.12338390e-01\n  8.88852338e-01  8.42384610e-01  9.59783581e-01  1.52548455e-01\n  9.39474793e-01  9.89534952e-02  9.01100352e-02  1.01685787e+00\n  1.23142391e+00  1.03022010e+00  7.01282744e-01  5.33403871e-01\n  3.27355879e-01  1.12338390e-01  9.96618878e-01  9.01261058e-01\n  4.82781920e-01  2.17968636e-01  3.86298075e-01  7.94215172e-02\n  2.99715436e-01  9.09898685e-01  8.70146307e-01  2.33750539e-01\n  3.20196524e-01 -9.50511497e-02  8.75525001e-02  8.43763195e-01\n  1.11760620e+00  1.03662366e+00  8.62235099e-01  2.43306107e-01\n  1.04509421e+00  6.77397009e-01  6.05309657e-01  5.33557586e-01\n -3.03562115e-02  9.31144249e-01  1.00837586e-02  9.11966732e-01\n  1.70274638e-01  2.76133942e-01  6.86855246e-01  1.26499119e+00\n  8.45136635e-02  2.26524023e-01  9.75650430e-01  1.50335998e-01\n  1.12496504e+00  8.44354016e-01  2.65160813e-02 -1.31047837e-02\n  2.27308715e-01  4.93694442e-01  1.47693742e-01  3.11462330e-01\n  9.53177057e-01  9.27326624e-02 -6.49476677e-03 -7.32148921e-02\n  4.15729383e-02  1.09249233e+00  7.51364748e-01 -5.85047666e-02\n  9.99389792e-01  3.93909861e-01  1.34607451e-01  1.15708438e+00\n  1.80762791e-01 -9.73364848e-02  4.13633643e-01  8.48945207e-01\n  3.90021015e-01 -1.15691136e-01 -1.40183023e-01  1.95537236e-01\n  8.40944729e-02  1.59191689e-01  4.44045160e-01  1.20945990e+00\n -5.47937088e-02  1.10589481e+00 -1.13412928e-02  5.97370795e-02\n -7.19498007e-02  3.40101570e-01 -6.75637291e-02  1.21650629e+00\n -1.05103206e-01  1.04310715e+00  8.85361472e-01  1.01161888e+00\n  3.05632026e-01  2.94835133e-01  2.08269082e-02  8.03106217e-01\n -1.39980864e-01  1.01204987e+00 -7.92196603e-02  5.66043704e-03\n  7.43992089e-01  1.01151392e+00  8.28330843e-01  8.82222059e-01\n  1.01610334e+00  6.08502759e-01  6.60718787e-01 -3.99161444e-02\n  8.05282194e-01  9.18585246e-01  8.15572858e-01  1.11605088e-01\n  9.26911429e-01  2.17338673e-01 -4.09074712e-02  8.05801814e-02\n  1.11575574e+00  4.18856510e-01  7.93102765e-01  2.27722142e-02\n  8.00178303e-01  2.37853047e-01  4.50917529e-01  1.25605252e+00\n -1.55230774e-01  4.83366521e-02  5.49260771e-02  4.67776381e-01\n  1.36386478e-01  7.58597496e-01 -1.44905159e-01  7.46438973e-01\n  9.83521871e-01  8.38532866e-02 -1.08807069e-01  1.06117311e+00\n  1.04839035e+00 -1.05747319e-02  8.95213193e-01 -6.31428874e-02\n  6.62265395e-03  3.90021015e-01  8.44132516e-02  8.34700640e-01\n  9.03190390e-02  8.30008055e-01  9.51333696e-01  5.92756581e-01\n  3.50498196e-01  3.14134111e-01  1.81846895e-01  8.20061617e-02\n -3.74594546e-03  4.10246646e-01  6.75212125e-03  2.74970536e-02\n  1.17408610e+00  3.18871349e-01  9.44344073e-01  2.13967607e-02\n  6.91834951e-01  5.64245115e-01  9.25111675e-02 -9.42260084e-03\n  9.56411970e-01  1.29284576e+00  1.02437115e+00 -9.62878997e-04\n  1.83689379e-02 -1.18436375e-01  1.63092107e-01 -9.01747236e-02\n  8.79697048e-01  6.14785806e-01  6.01592765e-01  9.21916539e-01\n  9.42088495e-01 -2.98382254e-01  7.53694214e-01  3.68570474e-01\n  1.31913023e-01  4.92476129e-01  3.94136261e-01  2.97426263e-01\n -5.99164423e-02  8.09238579e-01  7.92545930e-01  9.13499416e-01\n  5.99979229e-01 -4.93523248e-02 -1.02818652e-01  3.90021015e-01\n -1.17669738e-01  4.11474245e-01  4.14213599e-01  8.95802685e-02\n  8.35854408e-02 -4.75739555e-02  8.93906923e-01  4.88738457e-01\n  4.41872500e-01  8.58673036e-01  6.98238859e-01  3.65971458e-01\n -1.58843386e-02  2.84362906e-01  4.22754665e-02  1.41650290e-01\n  7.55083197e-01  9.69250408e-01  4.54680954e-01 -2.03577281e-02\n  1.41612235e-02  5.25200604e-02  1.19826462e+00  1.02874219e-01\n  1.82046643e-01  9.04809144e-01  8.16070856e-01  3.22273243e-01\n  5.51932370e-02  7.29845215e-01  3.94028568e-02  9.96335584e-01\n  7.49379817e-01  6.05696106e-01  7.61828437e-01  1.79183435e-01\n  4.59393828e-01  9.46064191e-01 -1.51222984e-01  9.20550199e-01\n  9.42162857e-01  9.97729917e-01  5.91094900e-01  2.47997069e-01\n  4.46488474e-02 -2.82861261e-02  3.63695395e-01  7.93936465e-01\n -1.13385965e-02 -1.37684378e-01  2.19708109e-01  3.53807572e-02\n -2.04594049e-02  9.90419103e-01  8.58201940e-01 -1.03083996e-01\n -3.80169929e-02  7.16989154e-01  3.21231583e-01  7.19230385e-01\n  2.32714286e-01 -1.22059042e-01  3.71177521e-02  7.58129845e-01\n  9.50348944e-01  8.01318518e-01  3.28253620e-01 -2.56494044e-02\n  1.01979201e-01  5.56969311e-01  3.88957006e-01  5.32022143e-02\n  3.72897785e-01  9.98233957e-01  9.53231006e-01  7.89885076e-01\n  9.71053416e-01  1.03609008e+00  1.24086765e-01  3.70397838e-01\n  9.70756013e-01  8.50416382e-01  1.14109840e+00  7.81418816e-01\n  2.94416433e-01  9.82952431e-01 -4.23408575e-02 -9.40469357e-03\n  9.28792790e-02  8.55182550e-01  1.16274706e-02  1.72478131e-01\n  7.64648738e-01 -1.70464824e-01  3.14293204e-01  9.14327170e-01\n  8.59076104e-01 -8.51843497e-02  1.18680598e+00  9.48526793e-01\n  1.37674778e+00  2.02291988e-01  9.21339256e-01 -7.26517596e-02\n  1.13962659e+00 -1.88850137e-01  8.85689802e-02  5.39300975e-01\n  1.17114610e-01 -6.02410531e-02  6.93567431e-01  4.82242261e-01\n  9.30086722e-01  9.86043238e-01  2.58949959e-02  8.35426117e-01\n  2.92430704e-01  5.69131909e-01  1.01604192e+00  4.87204162e-02\n  7.71440654e-01  3.60251168e-02  8.80857563e-01  6.26579042e-01\n  1.61988571e-01  5.89794035e-01  9.13246091e-01  1.14138689e+00\n  4.34923755e-02  1.42333989e-01 -1.00166326e-01  6.21965346e-01\n  3.25707654e-01  9.04758764e-01  4.90404330e-03  3.90021015e-01\n  1.05383410e+00 -1.03460637e-01  1.04112262e+00 -5.91872362e-03\n  6.76387771e-01  9.09055157e-03 -1.11673011e-01  1.44010900e+00\n  1.80053442e-01  7.29443527e-01  9.42434905e-01 -8.45645455e-02\n  9.01294240e-01  9.44032073e-01  1.01180979e+00  3.53884880e-01\n  8.90700170e-01  7.39719821e-01  3.57588930e-01  9.80049384e-01\n  1.55794350e+00  2.00178459e-01  1.45909642e+00  8.78103443e-01\n  2.68900878e-01  9.86025379e-03  8.87796311e-01  1.24210117e+00\n  1.40541597e-01  8.42622235e-02  1.40863061e-01  3.78082501e-01\n  2.35989513e-01 -1.37591139e-01  5.89242124e-02  6.85498892e-01\n  7.89028106e-01  9.72974600e-01  9.20704323e-01  3.69472182e-01\n  9.84439182e-01  8.18858179e-01  2.18990730e-01  9.01573180e-01\n  1.15142239e+00  1.20214356e+00  7.61727512e-01  7.31968769e-01\n  8.85884880e-01  8.77674085e-01  9.15956518e-01  8.89346909e-01\n -1.06658892e-01  7.74926049e-01  2.79275154e-01 -4.35389860e-04\n  1.72055245e-01  2.66210451e-01 -1.69166114e-01  7.47482786e-01\n  9.63997454e-01  1.35878255e-01  2.61648781e-01  1.03143497e-01\n  3.90021015e-01 -3.89321589e-02  3.78269345e-01  1.00868722e+00\n  2.13737912e-01  1.02077225e+00  1.77402942e-01  9.08903086e-01\n -3.42213444e-02  8.27027138e-01  1.15338334e+00  1.05853155e+00\n  1.71174152e-01  8.70505620e-01  4.69387094e-01  3.13506292e-01\n  7.74957992e-01  8.51121003e-01 -4.78246824e-02  1.11969048e+00\n  1.32328388e-01  8.00851338e-01 -2.87292487e-01  5.99047864e-01\n  4.19651325e-02  1.03731039e-01  1.61281045e-01  5.90909099e-01\n -6.65023884e-02  1.35796528e-01  3.88865176e-02  1.06223981e+00\n  9.63016113e-01  4.01579473e-01  7.13975846e-01 -3.26286534e-02\n  9.65584150e-01 -1.04578359e-02  7.15371046e-01  2.27421837e-03\n  7.80245478e-02  8.46095319e-02  4.89698294e-01  9.70647027e-01\n  4.20533312e-02 -1.10436796e-02  8.90668676e-01  1.09118974e+00\n  8.52224659e-01 -4.80178404e-02  9.57143929e-01  2.18082836e-01\n  3.90021015e-01  9.04242500e-01  4.14158325e-01 -1.19504872e-01\n  5.07508487e-01  1.09342528e+00  1.03339941e+00  9.37595347e-01\n  2.24568938e-01  8.71961519e-01 -4.04318660e-02 -2.39544974e-02]\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "deepnote_to_be_reexecuted": false,
    "source_hash": "d973b3b1",
    "execution_start": 1650301889013,
    "execution_millis": 34,
    "cell_id": "00009-44f2ed75-ce10-45c5-aa95-427fd2488721",
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 570
   },
   "source": "m = y_test.shape[0]\ntp=0\ntn=0\nfp=0\nfn=0\nfor i in range(m):\n    if (y_pred[i]==0 and (y_test[i]!=y_pred[i])):\n        fn+=1\n    elif (y_pred[i]==1 and (y_test[i]!=y_pred[i])):\n        fp+=1\n    elif (y_pred[i]==0 and (y_test[i]==y_pred[i])):\n        tn+=1\n    elif (y_pred[i]==1 and (y_test[i]==y_pred[i])):\n        tp+=1\n\nprecision=(tp)/(tp+fp)*100\nrecall=(tp)/(tp+fn)*100\nprint(\"Accuracy = \" + format((tp+tn)/(tp+tn+fp+fn)*100, '.2f') + \"%\")   \nprint(\"F1-Score = \" + format(((2*precision*recall)/(precision+recall)), '.2f') + \"%\")   \nprint(\"Recall = \" + format((tp)/(tp+fn)*100, '.2f') + \"%\")   \nprint(\"Precision = \" + format((tp)/(tp+fp)*100, '.2f') + \"%\")   \nprint(\"Specificity = \" + format((tn)/(tn+fp)*100, '.2f') + \"%\")  ",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "text": "Accuracy = 87.30%\nF1-Score = 86.45%\nRecall = 86.72%\nPrecision = 86.17%\nSpecificity = 87.80%\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "deepnote_to_be_reexecuted": false,
    "source_hash": "714f65a4",
    "execution_start": 1650301889048,
    "execution_millis": 291,
    "cell_id": "00013-f4c2816b-b0ed-42ea-a7d2-204effabc2a3",
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 565.9375,
    "deepnote_output_heights": [
     null,
     272.140625
    ]
   },
   "source": "# Draw the confusion matrix\ndef plot_cmat(y_test, ypred):\n    '''Plotting confusion matrix'''\n    skplt.plot_confusion_matrix(y_test, ypred)\n    plt.grid(False)\n    plt.show()\n    \nplot_cmat(y_test, y_pred)",
   "execution_count": null,
   "outputs": [
    {
     "name": "stderr",
     "text": "/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function plot_confusion_matrix is deprecated; This will be removed in v0.4.0. Please use scikitplot.metrics.plot_confusion_matrix instead.\n  warnings.warn(msg, category=FutureWarning)\n",
     "output_type": "stream"
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 2 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light",
      "image/png": {
       "width": 312,
       "height": 278
      }
     },
     "output_type": "display_data"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": "<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=3a2c2a1b-c190-4238-a7b0-93cabb99b4e1' target=\"_blank\">\n<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\nCreated in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>",
   "metadata": {
    "tags": [],
    "created_in_deepnote_cell": true,
    "deepnote_cell_type": "markdown"
   }
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 4,
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "deepnote_notebook_id": "ec058d6d-de2a-4e5b-98fc-3cdf8613ca91",
  "deepnote": {
   "is_reactive": false
  },
  "deepnote_execution_queue": []
 }
}